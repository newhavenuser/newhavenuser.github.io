---
title:
layout: docs  # Do not modify.

# Optional header image (relative to `static/img/` folder).
header:
  caption: ""
  image: ""
---
<img border="0" src="headers.jpg">



<h2><b>Human Healthcare Pipeline</b></h2>
<p style="text-align:justify;text-justify:inter-ideograph;">
The research aligns with <span2><b>human healthcare pipeline</b></span2>, including the clinical diagnosis, surgery intervention and medical foundation models. With the multimodal medical data from patient examinations, our research can assist clinicans with diagnosis and assist surgeons with surgery. In particular, our research on multimodal medical foundation models can further support the entire healthcare pipeline.
</p>
<img border="0" src="research-1-pipeline.jpg" width="1200" height="600">
<hr />

<h2><b>Multimodal Clinical Diagnosis</b></h2>
<p style="text-align:justify;text-justify:inter-ideograph;">
Our research targets at the multimodal clinical diagnosis through AI training pipeline. The research focuses on addressing significant clinical challenges caused by <span2><b>imperfect medical data</b></span2>, including the low-quality data, modality-missing data, decentralized data, and coarse/noisy annotations. The research has been verified on diverse modalities, such as endoscopy, dermoscopy, pathology, radiology, ophthalmology, genetics, etc.
</p>
<h4 id="Selected-Publications">Selected Publications</h4>
<ul>
<li><b>[MedIA'23]</b> Medical Federated Learning with Joint Graph Purification for Noisy Label Learning [<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841523002360">Paper</a>] [<a href="https://github.com/CUHK-AIM-Group/FedGP">Code</a>]</li>
<li><b>[TMI'22]</b> Personalized Retrogress-Resilient Federated Learning Towards Imbalanced Medical Data [<a href="https://www.researchgate.net/publication/362120723_Personalized_Retrogress-Resilient_Federated_Learning_Towards_Imbalanced_Medical_Data">Paper</a>] [<a href="https://github.com/CityU-AIM-Group/PRR-Imbalance">Code</a>]</li>
<li><b>[MICCAI'22]</b> Discrepancy and Gradient-guided Multi-modal Knowledge Distillation for Pathological Glioma Grading (<span2><b>MICCAI Young Scientist Award</b></span2>, <span2><b>Oral</b></span2>) [<a href="https://link.springer.com/chapter/10.1007/978-3-031-16443-9_61">Paper</a>] [<a href="https://github.com/CUHK-AIM-Group/MultiModal-learning">Code</a>]</li>
<li><b>[AAAI'21]</b> Diagnose Like A Pathologist: Weakly-Supervised Pathologist-Tree Network for Slide-Level Immunohistochemical Scoring [<a href="https://www.researchgate.net/publication/350089153_Diagnose_Like_A_Pathologist_Weakly-Supervised_Pathologist-Tree_Network_for_Slide-Level_Immunohistochemical_Scoring">Paper</a>] [<a href="https://github.com/franciszchen/PTree-Net">Code</a>]</li>
<li><b>[TMI'21]</b> Super-Resolution Enhanced Medical Image Diagnosis with Sample Affinity Interaction [<a href="https://ieeexplore.ieee.org/document/9339901">Paper</a>] [<a href="https://github.com/franciszchen/SRD-SAI">Code</a>]</li>
</ul>
<img border="0" src="research-2-diagnosis.jpg" width="1200" height="600">
<hr />

<h2><b>Surgery Intervention Assistance</b></h2>
<p style="text-align:justify;text-justify:inter-ideograph;">
We have developed a <span2><b>surgeon-centric Surgery Copilot system</b></span2> to provide comprehensive assistance throughout the preoperative, intraoperative and postoperative processes. By understanding the surgeon's intention through voice commands, our Surgery Copilot system can automatically execute of various advanced surgical understanding algorithms, and further support surgical pipeline automation and embodied ultrasound scanning. The research enhances precision, efficiency, and safety in surgical intervention.
</p>
<h4 id="Selected-Publications">Selected Publications</h4>
<ul>
<li><b>[MICCAI'24]</b> Transforming Surgical Interventions with Embodied Intelligence for Ultrasound Robotics (<span2><b>Oral</b></span2>) [<a href="https://arxiv.org/pdf/2406.12651">Paper</a>] [<a href="https://github.com/franciszchen/EmbodiedUS">Code</a>]</li>
<li><b>[IROS'24]</b> ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding (<span2><b>Oral</b></span2>) [<a href="https://arxiv.org/pdf/2407.19435">Paper</a>] [<a href="https://github.com/Zonmgin-Zhang/ASI-Seg">Code</a>]</li>
<li><b>[BigData'24]</b> SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot [<a href="https://github.com/franciszchen/SurgBox">Code</a>]</li>
<li><b>[BIBM'24]</b> SurgFC: Multimodal Surgical Function Calling Framework on the Demand of Surgeons [<a href="https://arxiv.org/pdf/2405.08272">Paper</a>] [<a href="https://github.com/franciszchen/SurgFC">Code</a>]</li>
<li><b>[MICCAI'23]</b> Surgical Video Captioning with Mutual-Modal Concept Alignment (<span2><b>Early accepted</b></span2>) [<a href="https://link.springer.com/chapter/10.1007/978-3-031-43996-4_3">Paper</a>] [<a href="https://github.com/franciszchen/SCA-Net">Code</a>]</li>
</ul>
<img border="0" src="research-3-surgery.jpg" width="1200" height="600">
<hr />


<h2><b>Medical Foundation Models</b></h2>
<p style="text-align:justify;text-justify:inter-ideograph;">
Besides the diganosis and surgery, our research is exploring on medical foundation models to support more stages in human healthcare pipeline. Namely, these stages include <span2><b>triage</b></span2>, <span2><b>imaging</b></span2>, <span2><b>diagnosis</b></span2>, <span2><b>treatment</b></span2>, <span2><b>surgery</b></span2>, and <span2><b>rehabilitation</b></span2>, covering the entire spectrum of patient care. By driving the evolution of medical foundation models across these stages, our goal is to create a more seamless, efficient, and patient-centric healthcare system.
</p>
<h4 id="Selected-Publications">Selected Publications</h4>
<ul>
<li><b>[NeurIPS'24]</b> Flaws can be Applause: Unleashing Potential of Segmenting Ambiguous Objects in SAM [<a href="https://openreview.net/forum?id=vJSNsSFO95">Paper</a>] [<a href="https://a-sa-m.github.io/">Code</a>]</li>
<li><b>[JBHI'24]</b> Unified Multi-modal Diagnostic Framework with Reconstruction Pre-training and Heterogeneity-combat Tuning [<a href="https://ieeexplore.ieee.org/abstract/document/10488705">Paper</a>] [<a href="https://github.com/helenypzhang/UMD">Code</a>]</li>
<li><b>[MICCAI'24]</b> EndoUIC: Promptable Diffusion Transformer for Unified Illumination Correction in Capsule Endoscopy [<a href="https://arxiv.org/pdf/2406.13705">Paper</a>] [<a href="https://github.com/longbai1006/EndoUIC">Code</a>]</li>
<li><b>[MICCAI'24]</b> Endora: Video Generation Models as Endoscopy Simulators [<a href="https://arxiv.org/pdf/2403.11050">Paper</a>] [<a href="https://github.com/CUHK-AIM-Group/Endora">Code</a>]</li>
<li>More research coming soon ...</li>
</ul>
<img border="0" src="research-4-foundation.jpg" width="800" height="400">





              
